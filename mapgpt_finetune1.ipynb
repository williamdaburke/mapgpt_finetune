{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ipYTyXx1Z4QU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiT6bwGxLBr9",
        "outputId": "ee2f5246-51e8-472e-c38b-0c147b0c2ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jun 11 15:10:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mapgpt_finetune'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 3), reused 12 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (13/13), 73.94 KiB | 2.31 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/williamdaburke/mapgpt_finetune.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working/remote-ssh-kaggle-vscode/mapgpt_finetune\n"
          ]
        }
      ],
      "source": [
        "%cd mapgpt_finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "README.md     jupyter-tunnel.sh  mapgpt_finetune1.ipynb  setup.sh\n",
            "data.parquet  main.py\t\t requirements.txt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'PartialState' from 'accelerate' (/opt/conda/lib/python3.10/site-packages/accelerate/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1172\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m     default_hp_search_backend,\n\u001b[1;32m     42\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     43\u001b[0m     hp_params,\n\u001b[1;32m     44\u001b[0m     is_fairscale_available,\n\u001b[1;32m     45\u001b[0m     is_optuna_available,\n\u001b[1;32m     46\u001b[0m     is_ray_tune_available,\n\u001b[1;32m     47\u001b[0m     is_sigopt_available,\n\u001b[1;32m     48\u001b[0m     is_wandb_available,\n\u001b[1;32m     49\u001b[0m     run_hp_search_optuna,\n\u001b[1;32m     50\u001b[0m     run_hp_search_ray,\n\u001b[1;32m     51\u001b[0m     run_hp_search_sigopt,\n\u001b[1;32m     52\u001b[0m     run_hp_search_wandb,\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/integrations.py:71\u001b[0m\n\u001b[1;32m     69\u001b[0m             _has_neptune \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_callback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProgressCallback, TrainerCallback  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PREFIX_CHECKPOINT_DIR, BestRun, IntervalStrategy  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_callback.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntervalStrategy, has_length\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining_args\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:67\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PartialState\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'PartialState' from 'accelerate' (/opt/conda/lib/python3.10/site-packages/accelerate/__init__.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m/kaggle/working/remote-ssh-kaggle-vscode/mapgpt_finetune/main.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     DistilBertTokenizerFast,\n\u001b[1;32m     17\u001b[0m     DistilBertForSequenceClassification,\n\u001b[1;32m     18\u001b[0m     Trainer,\n\u001b[1;32m     19\u001b[0m     TrainingArguments\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(parquet_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1162\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1162\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1174\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1177\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'PartialState' from 'accelerate' (/opt/conda/lib/python3.10/site-packages/accelerate/__init__.py)"
          ]
        }
      ],
      "source": [
        "%run main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot5DpD2-aAsz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_raw = pd.read_parquet('data.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "moLayFXNaHod",
        "outputId": "bf16b89e-ad43-4399-a041-17bb5e81b1b4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_raw\",\n  \"rows\": 240,\n  \"fields\": [\n    {\n      \"column\": \"write_time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 189,\n        \"samples\": [\n          \"2024-07-17 17:50:17.650000 UTC\",\n          \"2024-07-17 17:50:17.732000 UTC\",\n          \"2024-08-01 10:15:30.123000 UTC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chat_history\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 183,\n        \"samples\": [\n          \"[{\\\"content\\\": \\\"find me some good vegetarian restaurants in the area\\\\\\\\nAI: I have found several vegetarian restaurants near you in Prague, Czech Republic. You can try Lehk\\u00e1 Hlava, Maitrea, and Vegtrug, all within 10 minutes.\\\\\\\\nHuman: Read me the reviews for Maitrea\\\\\\\\nAI: Maitrea has excellent reviews! Customers love the ambiance and the variety of dishes available.\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}]\",\n          \"[{\\\"content\\\": \\\"\\\\u0120tactics \\\\u0120pe \\\\\\\" ut con \\\\u0120d er \\\\u0120strategic ac \\\\u0120when \\\\u0120Regional \\\\u0120share / \\\\u0120tick \\\\u0120stepped @\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}, {\\\"content\\\": \\\"\\\\u0120buildup \\\\\\\" \\\\u0120clean \\\\u0120de he \\\\u0120loc \\\\u0120Regional \\\\u0120appre \\\\u0120m ory il \\\\u0120quick ; \\\\u010b \\\\u010b 2 / \\\\u0120H ________ ier ain \\\\u0120not \\\\u0120cho # el \\\\u0120r\\\\u00c3\\\\u00a9 \\\\u0120bell oni \\\\u010b 3 / \\\\u0120H T \\\\u0120exterior uff \\\\u0120var / ople # el \\\\u0120attest \\\\u0120mir ruct \\\\u0120relig ocide \\\\u010b 4 / \\\\u0120H \\\\u0120his essed \\\\u01202022 # el \\\\u0120orient illas Sea\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"ai\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false, \\\"tool_calls\\\": [], \\\"invalid_tool_calls\\\": []}, {\\\"content\\\": \\\"\\\\u0120swing \\\\u0120de rupt - \\\\u0120wor ak il \\\\u0120Christ \\\\u0120when \\\\u0120peers . \\\\u0120notice irements ke @\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}]\",\n          \"[{\\\"content\\\": \\\"What time does the next train to Boston leave?\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}, {\\\"content\\\": \\\"The next train to Boston departs in 15 minutes from platform 3.\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"ai\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false, \\\"tool_calls\\\": [], \\\"invalid_tool_calls\\\": []}, {\\\"content\\\": \\\"Can you tell me the weather in Boston?\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}, {\\\"content\\\": \\\"The current weather in Boston is sunny with a high of 75\\u00b0F and a low of 55\\u00b0F.\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"ai\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false, \\\"tool_calls\\\": [], \\\"invalid_tool_calls\\\": []}, {\\\"content\\\": \\\"What\\u2019s the best way to get to the train station?\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"human\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false}, {\\\"content\\\": \\\"The best way to get to the train station is by taking the subway line 2 to Downtown Crossing, then transfer to the Orange Line to Haymarket. It should take about 20 minutes.\\\", \\\"additional_kwargs\\\": {}, \\\"response_metadata\\\": {}, \\\"type\\\": \\\"ai\\\", \\\"name\\\": null, \\\"id\\\": null, \\\"example\\\": false, \\\"tool_calls\\\": [], \\\"invalid_tool_calls\\\": []}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_user_utterance\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 240,\n        \"samples\": [\n          \"Can you suggest any romantic Italian restaurants?\",\n          \"where's a good place to get pastries?\",\n          \"Take me to Sushi Dai.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"English\",\n          \"Korean\",\n          \"French\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"search_pois\",\n          \"search_music\",\n          \"no_action\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_raw"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-05274762-a3ce-410e-a9da-65d4275955fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>write_time</th>\n",
              "      <th>chat_history</th>\n",
              "      <th>last_user_utterance</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-08-05 14:45:22.123000 UTC</td>\n",
              "      <td>[{\"content\": \"Hello! Where can I find a good r...</td>\n",
              "      <td>Can you suggest a nice place for Italian food?</td>\n",
              "      <td>English</td>\n",
              "      <td>search_pois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-08-15 12:34:45.123000 UTC</td>\n",
              "      <td>[{\"content\": \"Hey there!\", \"additional_kwargs\"...</td>\n",
              "      <td>Are there any good Italian restaurants around ...</td>\n",
              "      <td>English</td>\n",
              "      <td>search_pois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-08-01 10:15:45.123000 UTC</td>\n",
              "      <td>[]</td>\n",
              "      <td>Can you suggest some local restaurants for din...</td>\n",
              "      <td>English</td>\n",
              "      <td>search_pois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-08-10 14:30:45.567000 UTC</td>\n",
              "      <td>[{\"content\": \"Hi there! What can I help you wi...</td>\n",
              "      <td>Do you know where I can find a good sci-fi boo...</td>\n",
              "      <td>English</td>\n",
              "      <td>search_pois</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-07-30 15:15:00.123000 UTC</td>\n",
              "      <td>[]</td>\n",
              "      <td>Can you recommend a good café nearby?</td>\n",
              "      <td>English</td>\n",
              "      <td>search_pois</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05274762-a3ce-410e-a9da-65d4275955fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05274762-a3ce-410e-a9da-65d4275955fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05274762-a3ce-410e-a9da-65d4275955fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-303c3524-5511-4eda-8109-f12ca3cbc8ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-303c3524-5511-4eda-8109-f12ca3cbc8ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-303c3524-5511-4eda-8109-f12ca3cbc8ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       write_time  \\\n",
              "0  2024-08-05 14:45:22.123000 UTC   \n",
              "1  2024-08-15 12:34:45.123000 UTC   \n",
              "2  2024-08-01 10:15:45.123000 UTC   \n",
              "3  2024-08-10 14:30:45.567000 UTC   \n",
              "4  2024-07-30 15:15:00.123000 UTC   \n",
              "\n",
              "                                        chat_history  \\\n",
              "0  [{\"content\": \"Hello! Where can I find a good r...   \n",
              "1  [{\"content\": \"Hey there!\", \"additional_kwargs\"...   \n",
              "2                                                 []   \n",
              "3  [{\"content\": \"Hi there! What can I help you wi...   \n",
              "4                                                 []   \n",
              "\n",
              "                                 last_user_utterance language        label  \n",
              "0     Can you suggest a nice place for Italian food?  English  search_pois  \n",
              "1  Are there any good Italian restaurants around ...  English  search_pois  \n",
              "2  Can you suggest some local restaurants for din...  English  search_pois  \n",
              "3  Do you know where I can find a good sci-fi boo...  English  search_pois  \n",
              "4              Can you recommend a good café nearby?  English  search_pois  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "yHkzlv6qMtgs",
        "outputId": "4875f9fa-f9d1-4c7b-fff5-49b00fff1d4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>English</th>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japanese</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Korean</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spanish</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>French</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>German</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "language\n",
              "English     174\n",
              "Japanese     30\n",
              "Korean       25\n",
              "Spanish       5\n",
              "French        5\n",
              "German        1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw['language'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "52s21v40NXKs",
        "outputId": "ab65039b-d18c-439e-d6a8-ede06a41225b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>search_music</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>control_navigation</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_action</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>search_pois</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>search_poi</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drivers_manual</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "search_music          50\n",
              "control_navigation    50\n",
              "no_action             50\n",
              "search_pois           40\n",
              "search_poi            30\n",
              "drivers_manual        20\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xduSA7_WaInr",
        "outputId": "3c979c76-f8d6-4f1a-c4cb-ad7e2a1ab74b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(240, 5)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_raw.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjucAb9Sa1q5"
      },
      "outputs": [],
      "source": [
        "df_raw.to_csv('data_mapgpt.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "javro-Vrbs4M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "df_raw = pd.read_csv(\"data_mapgpt.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjGHlUBwDxFj",
        "outputId": "0bd3b545-fdad-456d-f627-9afd24f7d5b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'content': 'Hey there!',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'Hello! What can I help you with today?',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []},\n",
              " {'content': \"I'm looking for a good restaurant for dinner.\",\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'What type of cuisine do you prefer?',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []},\n",
              " {'content': 'I feel like having some Italian food.',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'Great choice! Let me find some Italian restaurants near you.',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json.loads(df_raw[1:2].chat_history.tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtMiiyErDC92",
        "outputId": "34c60503-3ab7-4330-88e6-1000409b6413"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'content': 'Hello! Where can I find a good restaurant nearby?',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'Hi there! What type of cuisine are you in the mood for?',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []},\n",
              " {'content': \"I'm craving some Italian food.\",\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'There are a few great Italian restaurants around you, such as Trattoria Al Forno and Osteria Morini. Would you like more details?',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []},\n",
              " {'content': 'Yes, please provide the addresses.',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'human',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False},\n",
              " {'content': 'Trattoria Al Forno is located at 2000 Avenue of the Arts, and Osteria Morini is at 301 Water Street SE. Enjoy your meal!',\n",
              "  'additional_kwargs': {},\n",
              "  'response_metadata': {},\n",
              "  'type': 'ai',\n",
              "  'name': None,\n",
              "  'id': None,\n",
              "  'example': False,\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json.loads(df_raw.chat_history.head(1).tolist()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYYnfDxDL-le",
        "outputId": "73ce622a-b1aa-4d45-8ce1-54e0aec22037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'Hello! Where can I find a good restaurant nearby?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'Hi there! What type of cuisine are you in the mood for?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}, {'content': \"I'm craving some Italian food.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'There are a few great Italian restaurants around you, such as Trattoria Al Forno and Osteria Morini. Would you like more details?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}, {'content': 'Yes, please provide the addresses.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'Trattoria Al Forno is located at 2000 Avenue of the Arts, and Osteria Morini is at 301 Water Street SE. Enjoy your meal!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}]\n",
            "Hello! Where can I find a good restaurant nearby? [SEP] Hi there! What type of cuisine are you in the mood for? [SEP] I'm craving some Italian food. [SEP] There are a few great Italian restaurants around you, such as Trattoria Al Forno and Osteria Morini. Would you like more details? [SEP] Yes, please provide the addresses. [SEP] Trattoria Al Forno is located at 2000 Avenue of the Arts, and Osteria Morini is at 301 Water Street SE. Enjoy your meal!\n",
            "[{'content': 'Hey there!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'Hello! What can I help you with today?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}, {'content': \"I'm looking for a good restaurant for dinner.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'What type of cuisine do you prefer?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}, {'content': 'I feel like having some Italian food.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'Great choice! Let me find some Italian restaurants near you.', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}]\n",
            "Hey there! [SEP] Hello! What can I help you with today? [SEP] I'm looking for a good restaurant for dinner. [SEP] What type of cuisine do you prefer? [SEP] I feel like having some Italian food. [SEP] Great choice! Let me find some Italian restaurants near you.\n",
            "[]\n",
            "\n",
            "[{'content': 'Hi there! What can I help you with today?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False}, {'content': \"I'm looking for a good bookshop nearby.\", 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}, {'content': 'Sure! Are you interested in any particular genre or just browsing?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'ai', 'name': None, 'id': None, 'example': False}, {'content': 'I love fiction, especially science fiction and fantasy!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': None, 'example': False}]\n",
            "Hi there! What can I help you with today? [SEP] I'm looking for a good bookshop nearby. [SEP] Sure! Are you interested in any particular genre or just browsing? [SEP] I love fiction, especially science fiction and fantasy!\n",
            "[]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for idx, row in df_raw[:5].iterrows():\n",
        "  print(json.loads(row.chat_history))\n",
        "  print(' [SEP] '.join(x['content'] for x in json.loads(row['chat_history'])) if row['chat_history'] else '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3FF4VFjC57r"
      },
      "outputs": [],
      "source": [
        "# Optional: combine chat history and last user utterance\n",
        "def combine_context(row):\n",
        "    chat_history = ' [SEP] '.join(x['content'] for x in json.loads(row['chat_history']))\n",
        "    return f\"{chat_history} [SEP] {row['last_user_utterance']}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5QOKlTuCviB"
      },
      "outputs": [],
      "source": [
        "df_raw['combined_text'] = df_raw.apply(combine_context, axis=1)\n",
        "\n",
        "# Encode labels\n",
        "label2id = {label: idx for idx, label in enumerate(df_raw['label'].unique())}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "df_raw['label_id'] = df_raw['label'].map(label2id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNNREBnMaEgg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGD9xEu4PPwY"
      },
      "outputs": [],
      "source": [
        "# !python -m spacy download fr_core_news_sm\n",
        "# !python -m spacy download es_core_news_sm\n",
        "# !python -m spacy download ko_core_news_sm\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download ja_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1qdyWF4O3CV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "# Load spaCy models for supported languages\n",
        "spacy_models = {\n",
        "    'English': spacy.load('en_core_web_sm'),\n",
        "    'French': spacy.load('fr_core_news_sm'),\n",
        "    'Spanish': spacy.load('es_core_news_sm'),\n",
        "    'Korean': spacy.load('ko_core_news_sm'),\n",
        "    'German': spacy.load('de_core_news_sm'),\n",
        "    'Japanese': spacy.load('ja_core_news_sm')\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePPx15VdOiyB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "def remove_named_entities(text, lang_name):\n",
        "    nlp = spacy_models.get(lang_name)\n",
        "    if not nlp:\n",
        "        return text  # fallback: skip NER if no model\n",
        "    doc = nlp(text)\n",
        "    new_tokens = []\n",
        "    for token in doc:\n",
        "        if token.ent_type_:\n",
        "            new_tokens.append(f\"<{token.ent_type_}>\")\n",
        "        else:\n",
        "            new_tokens.append(token.text)\n",
        "    return \" \".join(new_tokens)\n",
        "\n",
        "def preprocess_multilingual(text, lang_name):\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_named_entities(text, lang_name)\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJbOn6_jcMLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxOv4le5R1Hz"
      },
      "outputs": [],
      "source": [
        "#df['clean_text'] = df.apply(lambda row: preprocess_multilingual(row['text_str'], row['language']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpudyA2VcNIG"
      },
      "outputs": [],
      "source": [
        "df_only_utterance_raw = df_raw.copy()\n",
        "df_combined_clean = df_raw.copy()\n",
        "df_only_utterance_clean = df_raw.copy()\n",
        "df_raw['text_str'] = df_raw['combined_text'].astype(str)\n",
        "df_only_utterance_raw['text_str'] = df_only_utterance_raw['last_user_utterance'].astype(str)\n",
        "df_combined_clean['text_str'] = df_combined_clean.apply(lambda row: preprocess_multilingual(row['combined_text'], row['language']), axis=1)\n",
        "df_only_utterance_clean['text_str'] = df_only_utterance_clean.apply(lambda row: preprocess_multilingual(row['last_user_utterance'], row['language']), axis=1)\n",
        "df = pd.concat([df_raw, df_only_utterance_raw, df_combined_clean, df_only_utterance_clean])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmtv8YHjNi07",
        "outputId": "63c38d7e-2b6d-46fa-baf3-7daaf53ac69a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(960, 9)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaaO7618NMxg"
      },
      "outputs": [],
      "source": [
        "# for idx, row in df[:5].iterrows():\n",
        "#   print(row.clean_text)\n",
        "#   print(synonym_replacement(row.clean_text))\n",
        "#   print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfzxCZDJNMTS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text_str'], df['label_id'], test_size=0.2, stratify=df['label_id'], random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqaMMMZCdAyO",
        "outputId": "c294b570-d1b4-4566-d484-f3776851f1c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 2. Tokenization\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "# 3. Dataset class\n",
        "class IntentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IntentDataset(train_encodings, list(train_labels))\n",
        "val_dataset = IntentDataset(val_encodings, list(val_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeZNlWajdETY",
        "outputId": "9c441e78-ea72-4121-c48e-46d87a4652d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4. Model and training setup\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-multilingual-cased',\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results3',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=20,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds = eval_pred.predictions.argmax(axis=1)\n",
        "    labels = eval_pred.label_ids\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        'f1_macro': f1_score(labels, preds, average='macro')\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "UfPtDRshdGhd",
        "outputId": "0c76f1cd-d91a-4015-aebc-a09afbd3325b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwilliamdaburke\u001b[0m (\u001b[33mwilliamdaburke-burke-consulting-ltd\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250610_153415-3ua2naeu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface/runs/3ua2naeu' target=\"_blank\">./results3</a></strong> to <a href='https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface' target=\"_blank\">https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface/runs/3ua2naeu' target=\"_blank\">https://wandb.ai/williamdaburke-burke-consulting-ltd/huggingface/runs/3ua2naeu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='769' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 769/1920 09:31 < 14:16, 1.34 it/s, Epoch 8/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.774500</td>\n",
              "      <td>0.697274</td>\n",
              "      <td>0.744792</td>\n",
              "      <td>0.617171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.211000</td>\n",
              "      <td>0.419033</td>\n",
              "      <td>0.901042</td>\n",
              "      <td>0.895565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.256700</td>\n",
              "      <td>0.299311</td>\n",
              "      <td>0.901042</td>\n",
              "      <td>0.890251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.110500</td>\n",
              "      <td>0.350736</td>\n",
              "      <td>0.911458</td>\n",
              "      <td>0.913965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.074900</td>\n",
              "      <td>0.142861</td>\n",
              "      <td>0.963542</td>\n",
              "      <td>0.963790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.161513</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.966328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.157598</td>\n",
              "      <td>0.963542</td>\n",
              "      <td>0.961858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.163137</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.957302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4f2265c2d8a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 5. Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2657\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial)\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m             \u001b[0;31m# Save optimizer and scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m             \u001b[0;31m# Save RNG state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3335\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3336\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3337\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3339\u001b[0m         \u001b[0;31m# Save SCHEDULER & SCALER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    945\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# 5. Train and evaluate\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "0z6bT8cudI4L",
        "outputId": "ee7235c7-ab02-409a-e24b-364456f334e8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-339461671>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final evaluation:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(\"Final evaluation:\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZSVRjujg3nl"
      },
      "outputs": [],
      "source": [
        "!rm -r ./results/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_m19MufdHeW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Save model and tokenizer\n",
        "model.save_pretrained(\"./intent_classifier_distilbert\")\n",
        "tokenizer.save_pretrained(\"./intent_classifier_distilbert\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jQjB19EV9Xo"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./intent_classifier_distilbert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-nz7XvxeWv4"
      },
      "outputs": [],
      "source": [
        "trainer.train(resume_from_checkpoint=\"./intent_classifier_distilbert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwjZYUUDVqRb"
      },
      "outputs": [],
      "source": [
        "# Find the latest checkpoint in the output directory to resume from\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Get the output directory from training_args\n",
        "output_dir = training_args.output_dir\n",
        "\n",
        "# Find all directories within the output_dir that look like checkpoints\n",
        "checkpoints = sorted(glob.glob(os.path.join(output_dir, \"checkpoint-*\")), key=os.path.getmtime)\n",
        "\n",
        "# Check if any checkpoints were found\n",
        "if checkpoints:\n",
        "    # Get the path to the latest checkpoint directory\n",
        "    latest_checkpoint_path = checkpoints[-1]\n",
        "    print(f\"Resuming training from the latest checkpoint: {latest_checkpoint_path}\")\n",
        "    # Resume training from the latest checkpoint\n",
        "    trainer.train(resume_from_checkpoint=latest_checkpoint_path)\n",
        "else:\n",
        "    print(\"No checkpoints found in the output directory to resume from.\")\n",
        "    # Optionally, you might want to handle this case, e.g., train from scratch again\n",
        "    # trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAaLsVXEWMqp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
